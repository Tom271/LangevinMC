In this report we have introduced Markov Chain Monte Carlo algorithms, with a particular focus on Langevin Monte Carlo methods. We then tested the performance of the algorithms based on a number of metrics and a broad range of parameters. Our main contribution is extending the work of \cite{Brosse18tULA} and producing a \textsc{Python} package ready for use by other researchers to implement their own methods to be tested against the algorithms we have presented here. As well as implementing their own methods, it is also written in a way that allows easy extension to different potentials and distributions. As well as this, we have extended the visualisation library of Rogozhnikov \cite{rogozhnikov2016hmc} to include LMC methods. This allows students and those newly introduced to the field to get an intuitive look at how these algorithms work, and the differences between them. 

We have shown that taming is a viable method of preventing divergence of Langevin-based algorithms and gives insight into a distribution when Metropolised algorithms are unable to, particularly in ill-conditioned problems. It is interesting to note the efficiency of the \texttt{LM} algorithm in particular, despite its relative simplicity. It does however suffer from divergence problems as \texttt{ULA}.

There is no simple answer as to which algorithm is `best'. Depending on the application, and the prior information given on the distribution, one could make the case for any of the algorithms presented here. If the general shape of the distribution is known and computational power is not a restriction, a simple Random Walk Metropolis algorithm may well be the best option, even in the superlinear case.

If very little is known about maxima of the distribution, the taming method is the best choice. It is able to quickly find the modes of the distribution without divergence, however once at the mode it often over estimates the width of the potential well.  This has provoked some investigation into `switching' methods, where the chain is initially started using \texttt{tULA} for a fixed time to find the mode, before switching to the \texttt{RWM} algorithm to better explore the well. This is the rationale behind the \texttt{HPH} algorithm in the package, however it has been omitted from the report due to a lack of theoretical justification. It may well turn out to be similar to existing adaptive time stepping methods, or tempering methods.

Higher order methods seem to come at too great a computational cost, especially in very high dimension, although the theory supporting them suggests that more work is to be done on the numerical implementation of such methods.

If this report has highlighted anything, it is that Metropolisation is not the final word in Langevin Monte Carlo, and other methods of approximating Langevin dynamics should be exploited and explored. Non-asymptotic bounds are of great importance in this area, as it is known that \texttt{MALA} converges in the limit but this is of little practical use. 

\subsection{Future Work}\label{subsec:future}
There are many possible ways in which the work presented here could be extended, both from a research and personal perspective. First, there is great scope for the improvement of our program. It is possible to add new analytic distributions to sample from, including those with non-smooth potentials as in \cite{durmus2018efficient}. Another obvious avenue would be to apply all the methods and analysis here to real (large) datasets, when the gradient is not known analytically. This would give the end user a much clearer impression of which algorithm to use in their given case. It would also slow down all gradient based methods as an unbiased estimator for the gradient would have to be calculated at every iteration. It may also be possible to speed up the higher order methods (\texttt{HOLA,tHOLA,tHOLAc}) by implementing a parallelised version, breaking up the complex iteration into smaller easier to manage sections. This in general is highly non-trivial due to the inherent dependence on the previous step in a Markov chain. Another important consideration is that of burn-in time. For the majority of our tests, we started from a minimiser of the potential well however our code is certainly not limited to this case. Doing so effectively removes any burn-in time as the chains are started in approximate stationarity. When started far away from the mode of a distribution, initial tests suggest taming is a highly preferable method to Metropolised algorithms. They take many more steps towards the mode, while Metropolised algorithms waste lots of time rejecting moves. In practice, this would greatly reduce the burn-in time -- a key feature of an effective MCMC method. 

It is also important that we test the accuracy of our measures. This is difficult, especially in high dimensions as no methods exist for numerically calculating the 2-Wasserstein metric that many of the theoretical bounds use. Furthermore, using kernel density estimation or histograms with few bins introduces an error that is difficult to quantify and reduce. Here we have only qualitative comparisons between metrics. This is a well known problem in numerical optimal transport and inherent in dealing with high dimensional datasets and problems.

Many other methods exist in MCMC that remain to be tested against the tamed algorithms, or incorporated in to our program. These include Hamiltonian Monte Carlo (HMC), manifold MALA (mMALA), underdamped Langevin Monte Carlo and stochastic gradient Langevin dynamics (SGLD) \cite{betancourt2017conceptual, Girolami2011,cheng2018,pitfalls}. For dealing with stiff problems, specific methods also exist that could be used as benchmarks for taming algorithms \cite{abdulle2013weak}. In the next section SGLD will be expanded on due to its popularity in machine learning and high dimensional problems. 

For the wider field, it is important that either `user-friendly' bounds on nonasymptotic error are developed in terms of a numerically implementable metric, or that methods are developed to accurately calculate the 2-Wasserstein metric. Even this will not solve the problem of approximating a high dimensional distribution using samples from a distribution; it is simply infeasible to be able to generate enough samples to get a good representation. 

