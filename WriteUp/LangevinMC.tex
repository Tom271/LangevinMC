\documentclass[a4paper]{article}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[left=2cm,right=2cm,bottom=2.5cm,top=2.5cm]{geometry}
\usepackage{fancyhdr}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{enumitem}

\setlength{\headheight}{14.5pt} 

% Theorem-like environments
	\let\oldref\ref 
	\renewcommand{\ref}[1]{(\oldref{#1})}
	\newtheorem{thm}{Theorem}[section]
	\newtheorem{cor}[thm]{Corollary}
	\newtheorem*{lemma}{Lemma}
	\newtheorem{prop}[thm]{Proposition}
	\theoremstyle{definition}
	\newtheorem*{note}{Note}
	\newtheorem{defn}[thm]{Definition}
	\newtheorem{ex}[thm]{Example}
	
	\newenvironment{solution}{\renewcommand\qedsymbol{$\square$}\begin{proof}[Solution]}{\end{proof}}
	
% Set header and footer
	\pagestyle{fancy}
	\fancyhf{}

% I like footnotes to be superscript letters rather than numbers
	\renewcommand{\thefootnote}{\alph{footnote}}    
	\setlist[enumerate,1]{label={\roman*)}}
	
% Define new commands for typesetting here
	\newcommand{\R}{\mathbb{R}}
	\renewcommand{\L}{\mathcal{L}}  
	\renewcommand{\epsilon}{\varepsilon}
	\newcommand{\e}{\mathrm{e}}

%Swap bullets for long dash in itemize
	\renewcommand\labelitemi{---}
	\renewcommand\qedsymbol{\(\blacksquare\)}

% Typesets derivatives nicely using roman d. Adapts size automatically. Stolen from https://tex.stackexchange.com/questions/135944/commath-and-ifinner/135985#135985
% \od{y}{x} is ordinary derivative, \pd{f}{x} is partial derivative. See commath documentation for others
	\usepackage{amsmath}
	\newcommand{\dif}{\mathop{}\!\mathrm{d}}
	\newcommand{\Dif}{\mathop{}\!\mathrm{D}}
	
	\makeatletter
	\newcommand{\spx}[1]{%
		\if\relax\detokenize{#1}\relax
		\expandafter\@gobble
		\else
		\expandafter\@firstofone
		\fi
		{^{#1}}%
	}
	\makeatother
	
	\newcommand\pd[3][]{\frac{\partial\spx{#1}#2}{\partial#3\spx{#1}}}
	\newcommand\tpd[3][]{\tfrac{\partial\spx{#1}#2}{\partial#3\spx{#1}}}
	\newcommand\dpd[3][]{\dfrac{\partial\spx{#1}#2}{\partial#3\spx{#1}}}
	
	\newcommand{\md}[6]{\frac{\partial\spx{#2}#1}{\partial#3\spx{#4}\partial#5\spx{#6}}}
	\newcommand{\tmd}[6]{\tfrac{\partial\spx{#2}#1}{\partial#3\spx{#4}\partial#5\spx{#6}}}
	\newcommand{\dmd}[6]{\dfrac{\partial\spx{#2}#1}{\partial#3\spx{#4}\partial#5\spx{#6}}}
	
	\newcommand{\od}[3][]{\frac{\dif\spx{#1}#2}{\dif#3\spx{#1}}}
	\newcommand{\tod}[3][]{\tfrac{\dif\spx{#1}#2}{\dif#3\spx{#1}}}
	\newcommand{\dod}[3][]{\dfrac{\dif\spx{#1}#2}{\dif#3\spx{#1}}}
	
	\newcommand{\genericdel}[4]{%
		\ifcase#3\relax
		\ifx#1.\else#1\fi#4\ifx#2.\else#2\fi\or
		\bigl#1#4\bigr#2\or
		\Bigl#1#4\Bigr#2\or
		\biggl#1#4\biggr#2\or
		\Biggl#1#4\Biggr#2\else
		\left#1#4\right#2\fi
	}
	\newcommand{\del}[2][-1]{\genericdel(){#1}{#2}}
	\newcommand{\set}[2][-1]{\genericdel\{\}{#1}{#2}}
	\let\cbr\set
	\newcommand{\sbr}[2][-1]{\genericdel[]{#1}{#2}}
	\let\intoo\del
	\let\intcc\sbr
	\newcommand{\intoc}[2][-1]{\genericdel(]{#1}{#2}}
	\newcommand{\intco}[2][-1]{\genericdel[){#1}{#2}}
	\newcommand{\eval}[2][-1]{\genericdel.|{#1}{#2}}
	\newcommand{\envert}[2][-1]{\genericdel||{#1}{#2}}
	\let\abs\envert
	\newcommand{\sVert}[1][0]{%
		\ifcase#1\relax
		\rvert\or\bigr|\or\Bigr|\or\biggr|\or\Biggr
		\fi
	}
	\newcommand{\enVert}[2][-1]{\genericdel\|\|{#1}{#2}}
	\let\norm\enVert
	\newcommand{\fullfunction}[5]{%
		\begin{array}{@{}r@{}r@{}c@{}l@{}}
			#1 \colon & #2 & {}\longrightarrow{} & #3 \\
			& #4 & {}\longmapsto{}     & #5
		\end{array}
	}
\title{Langevin MC}
\author{B. Han, T.M. Hodgson, M. Holden \& M. Puza}
\usepackage{palatino}
\begin{document}
	\maketitle 
	
	Aim? Sample efficiently from high dimensional distributions of the form \(\pi(x) = Z^{-1} e^{-U(x)}\) where \(Z\) is a normalising constant.\\
	How? Use Langevin Dynamics\\
	Wait, what LD is an SDE? Yup, use a variety of methods to simulate the dynamics of this SDE: ULA, MALA, LM, HOLA. Both tamed and coordinate-wise tamed!\\
	Why does this work? The invariant measure of the Langevin SDE is exactly what we need!\\
	What goes wrong with ULA? Good question, we can find that out to motivate introducing other methods!\\
	\section{Why Bother?}
	\section{Langevin Equation}
	The Langevin Equation is a stochastic differential equation (SDE) originally developed to model random particle motion. Indeed, molecular dynamics continues to use and propse novel methods based on the equation. It is given by 	\[\dif X_t = -\nabla U(X_t)\dif t +\sqrt{2\gamma}\dif W_t,\]
	where \(W_t\) is a \(d\)-dimensional Wiener process (Brownian motion). It can be shown that this equation has an invariant measure given by \(\pi(x)=Z^{-1}\e^{-U(x)}\) with \(Z\) a normalising constant -- not sure if this is worth verifying (\(\L^*\pi=0 \)). What requirements on \(U\) are necessary for the SDE to be geometrically ergodic?
	
	
	
		\subsection{Discretisation: Euler-Maruyama/LM/HOLA}
		We can discretise the Langevin SDE so that paths can be simulated numerically. The classic method is to use the Euler-Maruyama (EM) method. This gives the following iterative scheme:
		\[x_{n+1}=x_n - \gamma \nabla U(x) +\sqrt{2\gamma}Z_{n+1} \]
		where \(Z \sim N(0,1)\). This is equivalent to 
		\(x_{n+1} = \xi\) where \(\xi \sim N\left(x_n-\gamma \nabla U(x), 2\gamma I_n\right)\)
		
		When discretising an SDE, it is important to check that the invariant measure of the SDE is preserved. 
		
		In the Euler method, only a first order approximation is used. This can be extended by taking in to consideration more terms in the expansion. This leads to an iterative scheme defined as
		\subsection{Algorithms}
		\subsubsection{ULA}
		+++ Error/Convergence bounds, non-asymptotic and asymptotic? +++
		\subsubsection{Leimkuhler-Matthews}
		Leimkuhler and Matthews propose a non-Markovian scheme to sample from the target distribution
			+++ Error/Convergence bounds +++
		\subsubsection{Higher Order Langevin Approximation}
		\subsubsection{Random Walk Metropolis}
		

	\section{MALA}
	\cite{RT_MALA}
	One way to reduce the issues with the ULA algorithm, Roberts + Tweedie proposed the Metropolis adjusted Langevin algorithm (MALA). Adding a Metropolis rejection step preserves the invariant measure and increases the class of potentials for which the algorithm converges.
	+++ Convergence/Error bounds --- Non-asymptotic +++ 
	
	\section{Taming: Coordinate and otherwise}
	
	To deal with superlinear potentials was proposed by Roberts + Tweedie 1996 (MALTA), and also Brosse, Durmus, Moulines, Sabanis (201x) (we call tULA). These involve \emph{taming} the potential by scaling it as follows.
	
	\[G_{\gamma} = \frac{\nabla U(x)}{1+\gamma \|\nabla U(x)\|}\]
	
	
	 
	
	\section{Applications to Large Datasets}
		\subsection{Stochastic Gradient Langevin Dynamics}
		
		\bibliography{langevinMC.bib}
		\bibliographystyle{plain}
		
\end{document}
