\documentclass[a4paper]{article}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=2cm,right=2cm,bottom=2.5cm,top=2.5cm]{geometry}
\usepackage{fancyhdr}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{enumitem}

\setlength{\headheight}{14.5pt} 

% Theorem-like environments
\let\oldref\ref
\renewcommand{\ref}[1]{(\oldref{#1})}
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem*{lemma}{Lemma}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{definition}
\newtheorem*{note}{Note}
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Example}

\newenvironment{solution}{\renewcommand\qedsymbol{$\square$}\begin{proof}[Solution]}{\end{proof}}

% Set header and footer
\pagestyle{fancy}
\fancyhf{}

% I like footnotes to be superscript letters rather than numbers
\renewcommand{\thefootnote}{\alph{footnote}}    
\setlist[enumerate,1]{label={\roman*)}}

% Define new commands for typesetting here
\newcommand{\R}{\mathbb{R}}
\renewcommand{\L}{\mathcal{L}}  
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\e}{\mathrm{e}}

%Swap bullets for long dash in itemize
\renewcommand\labelitemi{---}
\renewcommand\qedsymbol{\(\blacksquare\)}

% Typesets derivatives nicely using roman d. Adapts size automatically. Stolen from https://tex.stackexchange.com/questions/135944/commath-and-ifinner/135985#135985
% \od{y}{x} is ordinary derivative, \pd{f}{x} is partial derivative. See commath documentation for others
\usepackage{amsmath}
\newcommand{\dif}{\mathop{}\!\mathrm{d}}
\newcommand{\Dif}{\mathop{}\!\mathrm{D}}

\makeatletter
\newcommand{\spx}[1]{%
	\if\relax\detokenize{#1}\relax
	\expandafter\@gobble
	\else
	\expandafter\@firstofone
	\fi
	{^{#1}}%
}
\makeatother

\newcommand\pd[3][]{\frac{\partial\spx{#1}#2}{\partial#3\spx{#1}}}
\newcommand\tpd[3][]{\tfrac{\partial\spx{#1}#2}{\partial#3\spx{#1}}}
\newcommand\dpd[3][]{\dfrac{\partial\spx{#1}#2}{\partial#3\spx{#1}}}

\newcommand{\md}[6]{\frac{\partial\spx{#2}#1}{\partial#3\spx{#4}\partial#5\spx{#6}}}
\newcommand{\tmd}[6]{\tfrac{\partial\spx{#2}#1}{\partial#3\spx{#4}\partial#5\spx{#6}}}
\newcommand{\dmd}[6]{\dfrac{\partial\spx{#2}#1}{\partial#3\spx{#4}\partial#5\spx{#6}}}

\newcommand{\od}[3][]{\frac{\dif\spx{#1}#2}{\dif#3\spx{#1}}}
\newcommand{\tod}[3][]{\tfrac{\dif\spx{#1}#2}{\dif#3\spx{#1}}}
\newcommand{\dod}[3][]{\dfrac{\dif\spx{#1}#2}{\dif#3\spx{#1}}}

\newcommand{\genericdel}[4]{%
	\ifcase#3\relax
	\ifx#1.\else#1\fi#4\ifx#2.\else#2\fi\or
	\bigl#1#4\bigr#2\or
	\Bigl#1#4\Bigr#2\or
	\biggl#1#4\biggr#2\or
	\Biggl#1#4\Biggr#2\else
	\left#1#4\right#2\fi
}
\newcommand{\del}[2][-1]{\genericdel(){#1}{#2}}
\newcommand{\set}[2][-1]{\genericdel\{\}{#1}{#2}}
\let\cbr\set
\newcommand{\sbr}[2][-1]{\genericdel[]{#1}{#2}}
\let\intoo\del
\let\intcc\sbr
\newcommand{\intoc}[2][-1]{\genericdel(]{#1}{#2}}
\newcommand{\intco}[2][-1]{\genericdel[){#1}{#2}}
\newcommand{\eval}[2][-1]{\genericdel.|{#1}{#2}}
\newcommand{\envert}[2][-1]{\genericdel||{#1}{#2}}
\let\abs\envert
\newcommand{\sVert}[1][0]{%
	\ifcase#1\relax
	\rvert\or\bigr|\or\Bigr|\or\biggr|\or\Biggr
	\fi
}
\newcommand{\enVert}[2][-1]{\genericdel\|\|{#1}{#2}}
\let\norm\enVert
\newcommand{\fullfunction}[5]{%
	\begin{array}{@{}r@{}r@{}c@{}l@{}}
		#1 \colon & #2 & {}\longrightarrow{} & #3 \\
		& #4 & {}\longmapsto{}     & #5
	\end{array}
}
\title{Langevin MC}
\author{B. Han, T.M. Hodgson, M. Holden \& M. Puza}

\begin{document}
	\begin{center}
		{\huge \underline{\textbf{Standard Notations}}}
	\end{center}
If you come across something that isn't in the list that is likely to come up, add it and post the document on slack/GitHub again so we're all aware of the update.\\
\\
Put notes or things that need to be changed inside plus signs so that Ctrl+F can be used to find. E.g. +++ Insert reference to foo here +++ . Also allows you to highlight uncertain areas for other people to check.\\

\begin{center}
	\begin{tabular}{cc}
		Diffusion & \(X_t\) \\
		Brownian Motion/Wiener Process & \(W_t\)\\
		Potential & \( U:\R^d \to  \R \) \\
		Random Variables & Uppercase math font e.g. \(X,Y,Z\) \\
		Normalisation Constant & mathcal Z i.e. \(\mathcal{Z}\)\\
		Iteration & \(X_k\) \\ 
		Step Size & \(h\) \\ 
		Taming Function & \(T\) \\ 
		Stationary/Target/ True distribution & \(\pi\) \\ 
		Normal random variables & \(Z\) \\ 
		Minimum function & \(\wedge\)   i.e. \(\min\lbrace t,s\rbrace = t\wedge s\) \\
		Maximum function & \(\vee\)   i.e. \(\max\lbrace t,s\rbrace = t\vee s\) \\  
		Dimension & \(d\) \\ 
		Proposed step & \(Y\) \\ 
		Lipschitz constant & \(L\) \\ 
		Strong convexity constant & \(m\) \\ 
		Number of iterations & \(N\) \\ 
		Startpoint  & \(X_0 = x_0\) \\ 
	\end{tabular} \\
\vspace{1cm}
The first ten are Langevin Monte Carlo (LMC) algorithms. Try and drop subscript where possible, it is ugly.\\
\vspace{1cm}
\end{center}
\bgroup
\def\arraystretch{1.25}
\begin{center}
\begin{tabular}{ccc}
	\textbf{Algorithm} & \textbf{Name} & \textbf{Stationary Distribution} \\ 
	Unadjusted Langevin Algorithm &\texttt{ ULA} & \(\pi^{\gamma}_{\text{\tiny  \sc ULA}}\)\\ 
	Tamed Unadjusted Langevin Algorithm &\texttt{ tULA} & \(\pi^{\gamma}_{\text{ \tiny   tULA}}\) \\ 
	Coordinatewise Tamed Unadjusted Langevin Algorithm & \texttt{\tiny tULAc} & \(\pi^{\gamma}_{\text{ \tiny tULAc}}\) \\ 
	&  \\ 
	Metropolis Adjusted Langevin Algorithm & \texttt{MALA} & \(\pi^{\gamma}_{\text{\tiny MALA}}\) \\ 
	Tamed Metropolis Adjusted Langevin Algorithm & \texttt{tMALA} & \(\pi^{\gamma}_{\text{\tiny tMALA}}\) \\ 
	Coordinatewise Tamed Metropolis Adjusted Langevin Algorithm & \texttt{\tiny tMALAc} & \(\pi^{\gamma}_{\text{\tiny tMALAc}}\) \\ 
	Metropolis Adjusted Langevin Truncated  Algorithm & \texttt{MALTA } & \(\pi^{\gamma}_{\text{\tiny MALTA}}\)\\ 
	&  \\ 
	Higher Order Langevin Algorithm & \texttt{HOLA} & \(\pi^{\gamma}_{\text{\tiny HOLA}}\) \\ 
	Tamed Higher Order Langevin Algorithm & \texttt{tHOLA}  & \(\pi^{\gamma}_{\text{\tiny tHOLA}}\)\\ 
	Coordinatewise Tamed Higher Order Langevin Algorithm & \texttt{tHOLAc}&  \(\pi^{\gamma}_{\text{\tiny tHOLAc}}\) \\ 
	&  \\ 
	Leimkuhler-Matthews Algorithm & \texttt{LM} & \(\pi^{\gamma}_{\text{\tiny LM}}\) \\ 
	Tamed Leimkuhler-Matthews Algorithm & \texttt{tLM} & \(\pi^{\gamma}_{\text{\tiny tLM}}\)\\ 
	Coordinatewise Tamed Leimkuhler-Matthews Algorithm & \texttt{ tLMc} & \(\pi^{\gamma}_{\text{\tiny tLMc}}\) \\ 
	&  \\ 
	Random Walk Metropolis Algorithm & \texttt{RWM} & \(\pi^{\gamma}_{\text{\tiny RWM}}\) \\ 
\end{tabular} 
\end{center}


Assumptions on drift coefficient (taming)
\begin{enumerate}[label={\bf A{\arabic*}}]
	\item  For all \(h>0, G_h\) is continuous. There exist \(\alpha\geq 0, C_{\alpha}<+\infty\) such that for all \(h >0 \) and \(x \in \R^d\),
	\[\|G_h(x)-\nabla U(x)\| \leq hC_{\alpha}(1+\|x\|^{\alpha}).\]
	\item For all \(h>0\),
	\[ \liminf_{\|x\|\to \infty} \bigg\lbrack \bigg\langle \frac{x}{\|x\|}, G_h(x)\bigg\rangle - \frac{h}{2\|x\|}\|G_h(x)\|^2\bigg\rbrack >0\]
\end{enumerate}
\textbf{Assumptions}\\
In the last Chapter, we focus on the fixed step-size SGLD algorithm and assess its ability to reliably sample from Ï€
For that purpose and to quantify precisely the relation between LMC, SGLD, SGDFP and SGD, we make for simplicity the
following assumptions on U. \cite{pitfalls}
\begin{enumerate}[label={\bf H\arabic*}]
    \item    For all $i \in \{0,...,N\}, \ U_i$ is four times continuously differentiable and for all $j \in \{2, 3, 4\},$$sup_{\theta \in \mathbb{R}^d}||D^j U_i(\theta)||\leq \Tilde{L}.$ In particular for all $i\in \{0, ..., N\}$, $U_i$ $\Tilde{L}$-gradient Lipschitz, i.e. for all $\theta_1, \theta_2\in \mathbb{R}^d$, $||\nabla U_i(\theta_1) - \nabla U_i (\theta_2)|| \leq \Tilde{L}||\theta_1 - \theta_2||.$
    \item U is m-strongly convex, i.e. for all $\theta_1, \theta_2 \in \mathbb{R}^d$,$\left< \nabla U(\theta_1) - \nabla U(\theta_2), \theta_1 - \theta_2\right>\geq m ||\theta_1 - \theta_2||^2.$
    \item For all $i\in\{0,...,N\}$, $U_i$ is convex.
\end{enumerate}
\end{document}
