{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s1415551\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:84: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\s1415551\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:269: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\s1415551\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:94: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Algorithm: ULA\n",
      "Dimension: 2\n",
      "N: 10000000000\n",
      "Burn in: 1\n",
      "Number of simulations: 5\n",
      "Step: 0.01\n",
      "Timer: 1s\n",
      "x0[0]: 1.0\n",
      "#################\n",
      "\n",
      "Run of ULA finished, with 49142 iterations. m1[0], m2[0], acc = (-365.69099947504515, 0.8959876142832808, [])\n",
      "Run of ULA finished, with 40873 iterations. m1[0], m2[0], acc = (-5513.7242370460635, 1.054474955523816, [])\n",
      "Run of ULA finished, with 36523 iterations. m1[0], m2[0], acc = (7352.21384469625, 1.0957656300192908, [])\n",
      "Run of ULA finished, with 44917 iterations. m1[0], m2[0], acc = (-1663.3256249196331, 1.035852802527871, [])\n",
      "Run of ULA finished, with 35667 iterations. m1[0], m2[0], acc = (-1193.823600643445, 0.9416679652558719, [])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import normal, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "from time import clock\n",
    "\n",
    "class Potential:\n",
    "    \"\"\" Represents a potential function. \"\"\"\n",
    "    def __init__(self, potential=\"gaussian\", dimension=1):\n",
    "        self.dim = dimension\n",
    "        self.name = potential\n",
    "        # To add a potential, add it to the dictionary below and implement it/its gradient.\n",
    "        self.function, self.gradient, self.gradient2, self.vector_lap_grad = {\n",
    "            \"gaussian\":         (self.gaussian,         self.gaussian_grad,         None, None),\n",
    "            \"double_well\":      (self.double_well,      self.double_well_grad,      self.double_well_grad2, self.double_well_vector_lap_grad),\n",
    "            \"Ginzburg_Landau\":  (self.Ginzburg_Landau,  self.Ginzburg_Landau_grad,  None, None)\n",
    "        }[potential]\n",
    "\n",
    "        # Quantities to store in the Potential class, to avoid needless re-computation.\n",
    "        self.inv_sigma = 1. / np.arange(1, dimension+1, dtype=float) # for Gaussian\n",
    "\n",
    "    def gaussian(self, x):\n",
    "        return 0.5 * np.dot(x, np.multiply(self.inv_sigma, x))\n",
    "\n",
    "    def gaussian_grad(self, x):\n",
    "        return np.multiply(self.inv_sigma, x)\n",
    "\n",
    "    def double_well(self, x):\n",
    "        normx = norm(x)\n",
    "        return 0.25 * normx**4 - 0.5 * normx**2\n",
    "\n",
    "    def double_well_grad(self, x):\n",
    "        return (norm(x)**2 - 1) * x\n",
    "\n",
    "    def double_well_grad2(self, x):\n",
    "        mx = np.matrix(x)\n",
    "        return (norm(x)**2 - 1) * np.identity(self.dim) + 2 * np.transpose(mx) * mx\n",
    "\n",
    "    def double_well_vector_lap_grad(self, x):\n",
    "        return 6*x\n",
    "\n",
    "    def Ginzburg_Landau(self, x, tau=2.0, lamb=0.5, alpha=0.1):\n",
    "        d_ = round(self.dim ** (1./3))\n",
    "        x = np.reshape(x, (d_,d_,d_))\n",
    "        nabla_tilde = sum( norm(np.roll(x, -1, axis=a) - x)**2 for a in [0,1,2] )\n",
    "        return 0.5 * (1. - tau) * norm(x)**2 + \\\n",
    "               0.5 * tau * alpha * nabla_tilde + \\\n",
    "               0.25 * tau * lamb * np.sum(np.power(x, 4))\n",
    "\n",
    "    def Ginzburg_Landau_grad(self, x, tau=2.0, lamb=0.5, alpha=0.1):\n",
    "        d_ = round(self.dim ** (1./3))\n",
    "        x = np.reshape(x, (d_,d_,d_))\n",
    "        temp = sum( np.roll(x, sgn, axis=a) for sgn in [-1,1] for a in [0,1,2] )\n",
    "        return ((1. - tau) * x + \\\n",
    "                tau * lamb * np.power(x, 3) + \\\n",
    "                tau * alpha * (6*x - temp)).flatten()\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\" Evaluates a set of Langevin algorithms on given potentials. \"\"\"\n",
    "    def __init__(self, potential=\"gaussian\", dimension=1, N=10**2, burn_in=10**2, N_sim=5, x0=[0], step=0.01, timer=None):\n",
    "        self.dim = dimension\n",
    "        # To add an algorithm, add it to the dictionary below and implement it as a class method.\n",
    "        self.algorithms = {\n",
    "            \"ULA\":     self.ULA,\n",
    "            \"tULA\":    self.tULA,\n",
    "            \"tULAc\":   self.tULAc,\n",
    "            \"MALA\":    self.MALA,\n",
    "            \"RWM\":     self.RWM,\n",
    "            \"tMALA\":   self.tMALA,\n",
    "            \"tMALAc\":  self.tMALAc,\n",
    "            \"tHOLA\":   self.tHOLA,\n",
    "            \"LM\":      self.LM,\n",
    "            \"tLM\":     self.tLM,\n",
    "            \"tLMc\":    self.tLMc\n",
    "        }\n",
    "        self.N = N\n",
    "        self.burn_in = burn_in\n",
    "        self.N_sim = N_sim\n",
    "        self.x0 = x0\n",
    "        self.step = step\n",
    "        self.timer = timer\n",
    "        if timer:\n",
    "            self.N = 10**10 # ~~practically infinity\n",
    "            self.start_time = clock()\n",
    "        self.potential = Potential(potential, dimension)\n",
    "        # invoked by self.potential.funtion(parameters), self.potential.gradient(parameters)\n",
    "\n",
    "    def ULA(self):\n",
    "        x = np.array(self.x0)\n",
    "        m1, m2 = np.zeros(self.dim, dtype=float), np.zeros(self.dim, dtype=float)\n",
    "        sqrtstep = np.sqrt(2*self.step)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1 += x\n",
    "                m2 += np.power(x, 2)\n",
    "            x += -self.step * self.potential.gradient(x) + sqrtstep * normal(size=self.dim)\n",
    "        return m1, m2/float(i+1-self.burn_in), i+1 #i+1 = no. of iterations\n",
    "\n",
    "    def tULA(self, taming=(lambda g, step: g/(1. + step*norm(g)))):\n",
    "        x = np.array(self.x0)\n",
    "        m1, m2 = np.zeros(self.dim, dtype=float), np.zeros(self.dim, dtype=float)\n",
    "        sqrtstep = np.sqrt(2*self.step)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1 += x\n",
    "                m2 += np.power(x, 2)\n",
    "            x += -self.step * taming(self.potential.gradient(x), self.step) + sqrtstep * normal(size=self.dim)\n",
    "        return m1, m2/float(i+1-self.burn_in), i+1 #i+1 = no. of iterations\n",
    "\n",
    "    def tULAc(self):\n",
    "        # coordinate-wise taming function\n",
    "        return self.tULA(lambda g, step: np.divide(g, 1. + step*np.absolute(g)))\n",
    "\n",
    "    def MALA(self):\n",
    "        acc = 0 # acceptance probability\n",
    "        m1, m2 = np.zeros(self.dim, dtype=float), np.zeros(self.dim, dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1 += x\n",
    "                m2 += np.power(x, 2)\n",
    "            U_x, grad_U_x = self.potential.function(x), self.potential.gradient(x)\n",
    "            y = x - self.step * grad_U_x + np.sqrt(2 * self.step) * normal(size=self.dim)\n",
    "            U_y, grad_U_y = self.potential.function(y), self.potential.gradient(y)\n",
    "\n",
    "            logratio = -U_y + U_x + 1./(4*self.step) * (norm(y - x + self.step*grad_U_x)**2 \\\n",
    "                       -norm(x - y + self.step*grad_U_y)**2)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return m1, m2/float(i+1-self.burn_in), i+1, acc/float(i+1) #i+1 = no. of iterations\n",
    "\n",
    "    def RWM(self):\n",
    "        acc = 0 # acceptance probability\n",
    "        m1, m2 = np.zeros(self.dim, dtype=float), np.zeros(self.dim, dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1 += x\n",
    "                m2 += np.power(x, 2)\n",
    "            y = x + np.sqrt(2*self.step) * normal(self.dim)\n",
    "            logratio = self.potential.function(x) - self.potential.function(y)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return m1, m2/float(i+1-self.burn_in), i+1, acc/float(i+1) #i+1 = no. of iterations\n",
    "\n",
    "\n",
    "    def tMALA(self, taming=(lambda g, step: g/(1. + step*norm(g)))):\n",
    "        acc = 0 # acceptance probability\n",
    "        m1, m2 = np.zeros(self.dim, dtype=float), np.zeros(self.dim, dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1 += x\n",
    "                m2 += np.power(x, 2)\n",
    "            U_x, grad_U_x = self.potential.function(x), self.potential.gradient(x)\n",
    "            tamed_gUx = taming(grad_U_x, self.step)\n",
    "            y = x - self.step * tamed_gUx + np.sqrt(2*self.step) * normal(size=self.dim)\n",
    "            U_y, grad_U_y = self.potential.function(y), self.potential.gradient(y)\n",
    "            tamed_gUy = taming(grad_U_y, self.step)\n",
    "\n",
    "            logratio = -U_y + U_x + 1./(4*self.step) * (norm(y - x + self.step*tamed_gUx)**2 - norm(x - y + self.step*tamed_gUy)**2)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return m1, m2/float(i+1-self.burn_in), i+1, acc/float(i+1) #i+1 = no. of iterations\n",
    "\n",
    "    def tMALAc(self):\n",
    "        return self.tMALA(lambda g, step: np.divide(g, 1. + step * np.absolute(g)))\n",
    "\n",
    "    def tHOLA(self):\n",
    "        m1, m2 = np.zeros(self.dim, dtype=float), np.zeros(self.dim, dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1 += x\n",
    "                m2 += np.power(x, 2)\n",
    "\n",
    "            norm_x = norm(x)\n",
    "            grad_U = self.potential.gradient(x)\n",
    "            norm_grad_U = norm(grad_U)\n",
    "            grad_U_gamma = grad_U / (1 + (self.step * norm_grad_U)**1.5)**(2./3)\n",
    "            grad2_U = self.potential.gradient2(x)\n",
    "            norm_grad2_U = norm(grad2_U)\n",
    "            grad2_U_gamma = grad2_U / (1 + self.step * norm_grad2_U)\n",
    "\n",
    "            laplacian_grad_U = self.potential.vector_lap_grad(x)\n",
    "            laplacian_grad_U_gamma = laplacian_grad_U / (1 + self.step**0.5 * norm_x * norm(laplacian_grad_U))\n",
    "\n",
    "            grad2_U_grad_U_gamma = np.matmul(grad2_U, grad_U).A1 / (1 + self.step * norm_x * norm_grad2_U * norm_grad_U)\n",
    "\n",
    "            x += -self.step * grad_U_gamma + 0.5 * self.step**2 * (grad2_U_grad_U_gamma - laplacian_grad_U_gamma) + \\\n",
    "                  np.sqrt(2*self.step) * normal(size=self.dim) - np.sqrt(2) * np.matmul(grad2_U_gamma, normal(size=self.dim)).A1 * np.sqrt(self.step**3/3)\n",
    "\n",
    "        return m1, m2/float(i+1-self.burn_in), i+1 #i+1 = no. of iterations\n",
    "\n",
    "    def LM(self):\n",
    "        x = np.array(self.x0)\n",
    "        m1, m2 = np.zeros(self.dim, dtype=float), np.zeros(self.dim, dtype=float)\n",
    "        sqrtstep = np.sqrt(0.5 * self.step)\n",
    "        gaussian = normal(size=self.dim)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1 += x\n",
    "                m2 += np.power(x, 2)\n",
    "            gaussian_plus1 = normal(size=self.dim)\n",
    "            x += -self.step * self.potential.gradient(x) + sqrtstep * (gaussian + gaussian_plus1) * 0.5\n",
    "            gaussian = gaussian_plus1\n",
    "        return m1, m2/float(i+1-self.burn_in), i+1 #i+1 = no. of iterations\n",
    "\n",
    "    def tLM(self, taming=(lambda g, step: g/(1. + step * norm(g)))):\n",
    "        x = np.array(self.x0)\n",
    "        m1, m2 = np.zeros(self.dim, dtype=float), np.zeros(self.dim, dtype=float)\n",
    "        sqrtstep = np.sqrt(0.5 * self.step)\n",
    "        gaussian = normal(size=self.dim)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1 += x\n",
    "                m2 += np.power(x, 2)\n",
    "            gaussian_plus1 = normal(size=self.dim)\n",
    "            x += -self.step * taming(self.potential.gradient(x), self.step) + sqrtstep * (gaussian + gaussian_plus1) * 0.5\n",
    "            gaussian = gaussian_plus1\n",
    "        return m1, m2/float(i+1-self.burn_in), i+1 #i+1 = no. of iterations\n",
    "\n",
    "    def tLMc(self):\n",
    "        return self.tLM(lambda g, step: np.divide(g, 1. + step * np.absolute(g)))\n",
    "\n",
    "    def sampler(self, algorithm=\"ULA\"):\n",
    "        if self.timer:\n",
    "            self.start_time = clock()\n",
    "        return self.algorithms[algorithm]()\n",
    "\n",
    "    def analysis(self, algorithm=\"ULA\"):\n",
    "        print(f'\\n######### Algorithm: {algorithm}')\n",
    "        print(f'Dimension: {self.dim}\\nN: {self.N}\\nBurn in: {self.burn_in}\\nNumber of simulations: {self.N_sim}\\nStep: {self.step}\\nTimer: {self.timer}s\\nx0[0]: {self.x0[0]}')\n",
    "        print('#################\\n')\n",
    "\n",
    "        moment1, moment2, acceptances = [], [], []\n",
    "        for _ in range(self.N_sim):\n",
    "            m1, m2, iterations, *acc = self.sampler(algorithm)\n",
    "            if self.potential.name in ['double_well', 'Ginzburg_Landau']:\n",
    "                if norm(m1, np.inf) > 10:\n",
    "                    m1 = np.nan * m1\n",
    "                if norm(m2, np.inf) > 10:\n",
    "                    m2 = np.nan * m2\n",
    "            print(f'Run of {algorithm} finished, with {iterations} iterations. m1[0], m2[0], acc = {m1[0], m2[0], acc}')\n",
    "            moment1.append(m1)\n",
    "            moment2.append(m2)\n",
    "            if acc:\n",
    "                acceptances.append(acc[0])\n",
    "        return moment1, moment2, acceptances\n",
    "\n",
    "\n",
    "\n",
    "# TODO: RWM is buggy\n",
    "\n",
    "potential = 'gaussian'\n",
    "d = 2\n",
    "N = 100\n",
    "burn_in = 1 #10**4\n",
    "N_sim = 5\n",
    "x0 = np.array([1] + [1]*(d-1), dtype=float)\n",
    "step = 0.01\n",
    "\n",
    "# TIMER MODE: number of seconds which we allow the algorithms to run\n",
    "# To run normally without a timer, omit the last parameter\n",
    "timer = 1\n",
    "e = Evaluator(potential, dimension=d, N=N, burn_in=burn_in, N_sim=N_sim, x0=x0, step=step, timer=timer)\n",
    "\n",
    "algorithms = ['ULA']#'tULA', 'tULAc', 'MALA', 'tMALA', 'tMALAc', 'LM', 'tLM', 'tLMc']\n",
    "\n",
    "# First moments. for Gaussian, we take norm, for well and Ginzburg, we take the first coordinate\n",
    "data = [[norm(p) if potential=='gaussian' else p[0] for p in e.analysis(algo)[0]] for algo in algorithms]\n",
    "\n",
    "#plt.plot(data)\n",
    "# Boxplots\n",
    "#plt.title(f'Potential: {potential.upper()}\\nDim={d}, {\"Timer\" if e.timer else \"N\"}={timer if e.timer else N}\\nburn_in={burn_in}, N_sim={N_sim}, step={step}, x0[0]={x0[0]}')\n",
    "#plt.boxplot(data, labels=algorithms)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Algorithm: MALA\n",
      "Dimension: 2\n",
      "N: 10000000000\n",
      "Burn in: 1\n",
      "Number of simulations: 1\n",
      "Step: 0.01\n",
      "Timer: 1s\n",
      "x0[0]: 1.0\n",
      "#################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s1415551\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\s1415551\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:128: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-0697c117fc5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;31m# First moments. for Gaussian, we take norm, for well and Ginzburg, we take the first coordinate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpotential\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'gaussian'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-0697c117fc5a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;31m# First moments. for Gaussian, we take norm, for well and Ginzburg, we take the first coordinate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpotential\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'gaussian'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-0697c117fc5a>\u001b[0m in \u001b[0;36manalysis\u001b[1;34m(self, algorithm)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mmoment1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoment2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macceptances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN_sim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotential\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'double_well'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ginzburg_Landau'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-0697c117fc5a>\u001b[0m in \u001b[0;36msampler\u001b[1;34m(self, algorithm)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0manalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"RWM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-0697c117fc5a>\u001b[0m in \u001b[0;36mMALA\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mMALA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# acceptance probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import normal, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "from time import clock\n",
    "\n",
    "class Potential:\n",
    "    \"\"\" Represents a potential function. \"\"\"\n",
    "    def __init__(self, potential=\"gaussian\", dimension=1):\n",
    "        self.dim = dimension\n",
    "        self.name = potential\n",
    "        # To add a potential, add it to the dictionary below and implement it/its gradient.\n",
    "        self.function, self.gradient, self.gradient2, self.vector_lap_grad = {\n",
    "            \"gaussian\":         (self.gaussian,         self.gaussian_grad,         None, None),\n",
    "            \"double_well\":      (self.double_well,      self.double_well_grad,      self.double_well_grad2, self.double_well_vector_lap_grad),\n",
    "            \"Ginzburg_Landau\":  (self.Ginzburg_Landau,  self.Ginzburg_Landau_grad,  None, None)\n",
    "        }[potential]\n",
    "\n",
    "        # Quantities to store in the Potential class, to avoid needless re-computation.\n",
    "        self.inv_sigma = 1. / np.arange(1, dimension+1, dtype=float) # for Gaussian\n",
    "\n",
    "    def gaussian(self, x):\n",
    "        return 0.5 * np.dot(x, np.multiply(self.inv_sigma, x))\n",
    "\n",
    "    def gaussian_grad(self, x):\n",
    "        return np.multiply(self.inv_sigma, x)\n",
    "\n",
    "    def double_well(self, x):\n",
    "        normx = norm(x)\n",
    "        return 0.25 * normx**4 - 0.5 * normx**2\n",
    "\n",
    "    def double_well_grad(self, x):\n",
    "        return (norm(x)**2 - 1) * x\n",
    "\n",
    "    def double_well_grad2(self, x):\n",
    "        mx = np.matrix(x)\n",
    "        return (norm(x)**2 - 1) * np.identity(self.dim) + 2 * np.transpose(mx) * mx\n",
    "\n",
    "    def double_well_vector_lap_grad(self, x):\n",
    "        return 6*x\n",
    "\n",
    "    def Ginzburg_Landau(self, x, tau=2.0, lamb=0.5, alpha=0.1):\n",
    "        d_ = round(self.dim ** (1./3))\n",
    "        x = np.reshape(x, (d_,d_,d_))\n",
    "        nabla_tilde = sum( norm(np.roll(x, -1, axis=a) - x)**2 for a in [0,1,2] )\n",
    "        return 0.5 * (1. - tau) * norm(x)**2 + \\\n",
    "               0.5 * tau * alpha * nabla_tilde + \\\n",
    "               0.25 * tau * lamb * np.sum(np.power(x, 4))\n",
    "\n",
    "    def Ginzburg_Landau_grad(self, x, tau=2.0, lamb=0.5, alpha=0.1):\n",
    "        d_ = round(self.dim ** (1./3))\n",
    "        x = np.reshape(x, (d_,d_,d_))\n",
    "        temp = sum( np.roll(x, sgn, axis=a) for sgn in [-1,1] for a in [0,1,2] )\n",
    "        return ((1. - tau) * x + \\\n",
    "                tau * lamb * np.power(x, 3) + \\\n",
    "                tau * alpha * (6*x - temp)).flatten()\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\" Evaluates a set of Langevin algorithms on given potentials. \"\"\"\n",
    "    def __init__(self, potential=\"gaussian\", dimension=1, N=10**2, burn_in=10**2, N_sim=5, x0=[0], step=0.01, timer=None):\n",
    "        self.dim = dimension\n",
    "        # To add an algorithm, add it to the dictionary below and implement it as a class method.\n",
    "        self.algorithms = {\n",
    "            \"MALA\":    self.MALA,\n",
    "            \"RWM\":     self.RWM,\n",
    "        }\n",
    "        self.N = N\n",
    "        self.burn_in = burn_in\n",
    "        self.N_sim = N_sim\n",
    "        self.x0 = x0\n",
    "        self.step = step\n",
    "        self.timer = timer\n",
    "        if timer:\n",
    "            self.N = 10**10 # ~~practically infinity\n",
    "            self.start_time = clock()\n",
    "        self.potential = Potential(potential, dimension)\n",
    "        # invoked by self.potential.funtion(parameters), self.potential.gradient(parameters)\n",
    "    def MALA(self):\n",
    "        acc = 0 # acceptance probability\n",
    "        m1 = np.zeros([self.N,self.dim], dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1=np.append(m1, x)\n",
    "                np.reshape(m1, [i,self.dim])\n",
    "            U_x, grad_U_x = self.potential.function(x), self.potential.gradient(x)\n",
    "            y = x - self.step * grad_U_x + np.sqrt(2 * self.step) * normal(size=self.dim)\n",
    "            U_y, grad_U_y = self.potential.function(y), self.potential.gradient(y)\n",
    "\n",
    "            logratio = -U_y + U_x + 1./(4*self.step) * (norm(y - x + self.step*grad_U_x)**2 \\\n",
    "                       -norm(x - y + self.step*grad_U_y)**2)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return m1, i+1, acc/float(i+1) #i+1 = no. of iterations\n",
    "\n",
    "    def RWM(self):\n",
    "        acc = 0 # acceptance probability\n",
    "        m1 = np.zeros([self.N,self.dim], dtype=float)\n",
    "\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            if i >= self.burn_in:\n",
    "                m1=np.append(m1, x)\n",
    "                np.reshape(m1, [i,self.dim])\n",
    "            y = x + np.sqrt(2*self.step) * normal(self.dim)\n",
    "            logratio = self.potential.function(x) - self.potential.function(y)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return m1, i+1, acc/float(i+1) #i+1 = no. of iterations\n",
    "\n",
    "\n",
    "    def sampler(self, algorithm=\"RWM\"):\n",
    "        if self.timer:\n",
    "            self.start_time = clock()\n",
    "        return self.algorithms[algorithm]()\n",
    "\n",
    "    def analysis(self, algorithm=\"RWM\"):\n",
    "        print(f'\\n######### Algorithm: {algorithm}')\n",
    "        print(f'Dimension: {self.dim}\\nN: {self.N}\\nBurn in: {self.burn_in}\\nNumber of simulations: {self.N_sim}\\nStep: {self.step}\\nTimer: {self.timer}s\\nx0[0]: {self.x0[0]}')\n",
    "        print('#################\\n')\n",
    "\n",
    "        moment1, moment2, acceptances = [], [], []\n",
    "        for _ in range(self.N_sim):\n",
    "            m1, iterations, *acc = self.sampler(algorithm)\n",
    "            if self.potential.name in ['double_well', 'Ginzburg_Landau']:\n",
    "                if norm(m1, np.inf) > 10:\n",
    "                    m1 = np.nan * m1\n",
    "            print(f'Run of {algorithm} finished, with {iterations} iterations., m1[0], acc = {m1[0], acc}')\n",
    "            moment1.append(m1)\n",
    "            if acc:\n",
    "                acceptances.append(acc[0])\n",
    "        return moment1, moment2, acceptances\n",
    "\n",
    "\n",
    "\n",
    "# TODO: RWM is buggy\n",
    "\n",
    "potential = 'gaussian'\n",
    "d = 2\n",
    "N = 100\n",
    "burn_in = 1 #10**4\n",
    "N_sim = 1\n",
    "x0 = np.array([1] + [1]*(d-1), dtype=float)\n",
    "step = 0.01\n",
    "\n",
    "# TIMER MODE: number of seconds which we allow the algorithms to run\n",
    "# To run normally without a timer, omit the last parameter\n",
    "timer = 1\n",
    "e = Evaluator(potential, dimension=d, N=N, burn_in=burn_in, N_sim=N_sim, x0=x0, step=step, timer=timer)\n",
    "\n",
    "algorithms = [ 'MALA', 'RWM']\n",
    "\n",
    "# First moments. for Gaussian, we take norm, for well and Ginzburg, we take the first coordinate\n",
    "data = [[norm(p) if potential=='gaussian' else p[0] for p in e.analysis(algo)[0]] for algo in algorithms]\n",
    "\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import normal, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "from time import clock\n",
    "\n",
    "class Potential:\n",
    "    \"\"\" Represents a potential function. \"\"\"\n",
    "    def __init__(self, potential=\"gaussian\", dimension=1):\n",
    "        self.dim = dimension\n",
    "        self.name = potential\n",
    "        # To add a potential, add it to the dictionary below and implement it/its gradient.\n",
    "        self.function, self.gradient, self.gradient2, self.vector_lap_grad = {\n",
    "            \"gaussian\":         (self.gaussian,         self.gaussian_grad,         None, None),\n",
    "            \"double_well\":      (self.double_well,      self.double_well_grad,      self.double_well_grad2, self.double_well_vector_lap_grad),\n",
    "            \"Ginzburg_Landau\":  (self.Ginzburg_Landau,  self.Ginzburg_Landau_grad,  None, None)\n",
    "        }[potential]\n",
    "\n",
    "        # Quantities to store in the Potential class, to avoid needless re-computation.\n",
    "        self.inv_sigma = 1. / np.arange(1, dimension+1, dtype=float) # for Gaussian\n",
    "\n",
    "    def gaussian(self, x):\n",
    "        return 0.5 * np.dot(x, np.multiply(self.inv_sigma, x))\n",
    "\n",
    "    def gaussian_grad(self, x):\n",
    "        return np.multiply(self.inv_sigma, x)\n",
    "\n",
    "    def double_well(self, x):\n",
    "        normx = norm(x)\n",
    "        return 0.25 * normx**4 - 0.5 * normx**2\n",
    "\n",
    "    def double_well_grad(self, x):\n",
    "        return (norm(x)**2 - 1) * x\n",
    "\n",
    "    def double_well_grad2(self, x):\n",
    "        mx = np.matrix(x)\n",
    "        return (norm(x)**2 - 1) * np.identity(self.dim) + 2 * np.transpose(mx) * mx\n",
    "\n",
    "    def double_well_vector_lap_grad(self, x):\n",
    "        return 6*x\n",
    "\n",
    "    def Ginzburg_Landau(self, x, tau=2.0, lamb=0.5, alpha=0.1):\n",
    "        d_ = round(self.dim ** (1./3))\n",
    "        x = np.reshape(x, (d_,d_,d_))\n",
    "        nabla_tilde = sum( norm(np.roll(x, -1, axis=a) - x)**2 for a in [0,1,2] )\n",
    "        return 0.5 * (1. - tau) * norm(x)**2 + \\\n",
    "               0.5 * tau * alpha * nabla_tilde + \\\n",
    "               0.25 * tau * lamb * np.sum(np.power(x, 4))\n",
    "\n",
    "    def Ginzburg_Landau_grad(self, x, tau=2.0, lamb=0.5, alpha=0.1):\n",
    "        d_ = round(self.dim ** (1./3))\n",
    "        x = np.reshape(x, (d_,d_,d_))\n",
    "        temp = sum( np.roll(x, sgn, axis=a) for sgn in [-1,1] for a in [0,1,2] )\n",
    "        return ((1. - tau) * x + \\\n",
    "                tau * lamb * np.power(x, 3) + \\\n",
    "                tau * alpha * (6*x - temp)).flatten()\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\" Evaluates a set of Langevin algorithms on given potentials. \"\"\"\n",
    "    def __init__(self, potential=\"gaussian\", dimension=1, N=10**2, burn_in=10**2, N_sim=5, x0=[0], step=0.01, timer=None):\n",
    "        self.dim = dimension\n",
    "        # To add an algorithm, add it to the dictionary below and implement it as a class method.\n",
    "        self.algorithms = {\n",
    "            \"ULA\":     self.ULA,\n",
    "            \"tULA\":    self.tULA,\n",
    "            \"tULAc\":   self.tULAc,\n",
    "            \"MALA\":    self.MALA,\n",
    "            \"RWM\":     self.RWM,\n",
    "            \"tMALA\":   self.tMALA,\n",
    "            \"tMALAc\":  self.tMALAc,\n",
    "            \"tHOLA\":   self.tHOLA,\n",
    "            \"LM\":      self.LM,\n",
    "            \"tLM\":     self.tLM,\n",
    "            \"tLMc\":    self.tLMc\n",
    "        }\n",
    "        self.N = N\n",
    "        self.burn_in = burn_in\n",
    "        self.N_sim = N_sim\n",
    "        self.x0 = x0\n",
    "        self.step = step\n",
    "        self.timer = timer\n",
    "        if timer:\n",
    "            self.N = 10**10 # ~~practically infinity\n",
    "            self.start_time = clock()\n",
    "        self.potential = Potential(potential, dimension)\n",
    "        # invoked by self.potential.funtion(parameters), self.potential.gradient(parameters)\n",
    "    def ULA(self):\n",
    "        x = np.array(self.x0)\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        sqrtstep = np.sqrt(2*self.step)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "            sample[:,i]=x\n",
    "            x += -self.step * self.potential.gradient(x) + sqrtstep * normal(size=self.dim)\n",
    "\n",
    "        return sample #i+1 = no. of iterations\n",
    "\n",
    "    def tULA(self, taming=(lambda g, step: g/(1. + step*norm(g)))):\n",
    "        x = np.array(self.x0)\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        sqrtstep = np.sqrt(2*self.step)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            x += -self.step * taming(self.potential.gradient(x), self.step) + sqrtstep * normal(size=self.dim)\n",
    "        return sample\n",
    "\n",
    "    def tULAc(self):\n",
    "        # coordinate-wise taming function\n",
    "        return self.tULA(lambda g, step: np.divide(g, 1. + step*np.absolute(g)))\n",
    "\n",
    "    def MALA(self):\n",
    "        acc = 0 # acceptance probability\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            U_x, grad_U_x = self.potential.function(x), self.potential.gradient(x)\n",
    "            y = x - self.step * grad_U_x + np.sqrt(2 * self.step) * normal(size=self.dim)\n",
    "            U_y, grad_U_y = self.potential.function(y), self.potential.gradient(y)\n",
    "\n",
    "            logratio = -U_y + U_x + 1./(4*self.step) * (norm(y - x + self.step*grad_U_x)**2 \\\n",
    "                       -norm(x - y + self.step*grad_U_y)**2)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def RWM(self):\n",
    "        acc = 0 # acceptance probability\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            y = x + np.sqrt(2*self.step) * normal(self.dim)\n",
    "            logratio = self.potential.function(x) - self.potential.function(y)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def tMALA(self, taming=(lambda g, step: g/(1. + step*norm(g)))):\n",
    "        acc = 0 # acceptance probability\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            U_x, grad_U_x = self.potential.function(x), self.potential.gradient(x)\n",
    "            tamed_gUx = taming(grad_U_x, self.step)\n",
    "            y = x - self.step * tamed_gUx + np.sqrt(2*self.step) * normal(size=self.dim)\n",
    "            U_y, grad_U_y = self.potential.function(y), self.potential.gradient(y)\n",
    "            tamed_gUy = taming(grad_U_y, self.step)\n",
    "\n",
    "            logratio = -U_y + U_x + 1./(4*self.step) * (norm(y - x + self.step*tamed_gUx)**2 - norm(x - y + self.step*tamed_gUy)**2)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def tMALAc(self):\n",
    "        return self.tMALA(lambda g, step: np.divide(g, 1. + step * np.absolute(g)))\n",
    "\n",
    "    def tHOLA(self):\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            norm_x = norm(x)\n",
    "            grad_U = self.potential.gradient(x)\n",
    "            norm_grad_U = norm(grad_U)\n",
    "            grad_U_gamma = grad_U / (1 + (self.step * norm_grad_U)**1.5)**(2./3)\n",
    "            grad2_U = self.potential.gradient2(x)\n",
    "            norm_grad2_U = norm(grad2_U)\n",
    "            grad2_U_gamma = grad2_U / (1 + self.step * norm_grad2_U)\n",
    "\n",
    "            laplacian_grad_U = self.potential.vector_lap_grad(x)\n",
    "            laplacian_grad_U_gamma = laplacian_grad_U / (1 + self.step**0.5 * norm_x * norm(laplacian_grad_U))\n",
    "\n",
    "            grad2_U_grad_U_gamma = np.matmul(grad2_U, grad_U).A1 / (1 + self.step * norm_x * norm_grad2_U * norm_grad_U)\n",
    "\n",
    "            x += -self.step * grad_U_gamma + 0.5 * self.step**2 * (grad2_U_grad_U_gamma - laplacian_grad_U_gamma) + \\\n",
    "                  np.sqrt(2*self.step) * normal(size=self.dim) - np.sqrt(2) * np.matmul(grad2_U_gamma, normal(size=self.dim)).A1 * np.sqrt(self.step**3/3)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def LM(self):\n",
    "        x = np.array(self.x0)\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        sqrtstep = np.sqrt(0.5 * self.step)\n",
    "        gaussian = normal(size=self.dim)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            gaussian_plus1 = normal(size=self.dim)\n",
    "            x += -self.step * self.potential.gradient(x) + sqrtstep * (gaussian + gaussian_plus1) * 0.5\n",
    "            gaussian = gaussian_plus1\n",
    "        return sample\n",
    "\n",
    "    def tLM(self, taming=(lambda g, step: g/(1. + step * norm(g)))):\n",
    "        x = np.array(self.x0)\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        sqrtstep = np.sqrt(0.5 * self.step)\n",
    "        gaussian = normal(size=self.dim)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            gaussian_plus1 = normal(size=self.dim)\n",
    "            x += -self.step * taming(self.potential.gradient(x), self.step) + sqrtstep * (gaussian + gaussian_plus1) * 0.5\n",
    "            gaussian = gaussian_plus1\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def tLMc(self):\n",
    "        return self.tLM(lambda g, step: np.divide(g, 1. + step * np.absolute(g)))\n",
    "\n",
    "    def sampler(self, algorithm=\"ULA\"):\n",
    "        if self.timer:\n",
    "            self.start_time = clock()\n",
    "        return self.algorithms[algorithm]()\n",
    "\n",
    "potential = 'gaussian'\n",
    "d = 2\n",
    "N = 10**2\n",
    "burn_in = 0\n",
    "N_sim = 1\n",
    "x0 = np.array([10] + [10]*(d-1), dtype=float)\n",
    "step = 0.1\n",
    "\n",
    "# TIMER MODE: number of seconds which we allow the algorithms to run\n",
    "# To run normally without a timer, omit the last parameter\n",
    "timer = 2.5\n",
    "\n",
    "e = Evaluator(potential, dimension=d, N=N, burn_in=burn_in, N_sim=N_sim, x0=x0, step=step)\n",
    "\n",
    "\n",
    "ULA_data = e.sampler(\"ULA\")\n",
    "tULA_data = e.sampler(\"tULA\")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Trace\" )\n",
    "plt.plot(ULA_data[0],ULA_data[1],'r')\n",
    "plt.plot(tULA_data[0],tULA_data[1],'g')\n",
    "\n",
    "from matplotlib import cm\n",
    "from scipy.stats import multivariate_normal as MVN\n",
    "\n",
    "\"\"\"Plot heatmap of 2D MVN distribution \"\"\"\n",
    "# Our 2-dimensional distribution will be over variables X and Y\n",
    "N = 600\n",
    "X = np.linspace(min(np.append(ULA_data[0], tULA_data[0])), max(np.append(ULA_data[0],tULA_data[0])), N)\n",
    "Y = np.linspace(min(np.append(ULA_data[1], tULA_data[1])), max(np.append(ULA_data[1],tULA_data[1])), N)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "# Mean vector and covariance matrix\n",
    "mu = np.array([0., 0])\n",
    "Sigma = np.diag(np.arange(1, 3, dtype=float))\n",
    "\n",
    "# Pack X and Y into a single 3-dimensional array\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y\n",
    "\n",
    "F = MVN(mu, Sigma)\n",
    "Z = F.pdf(pos)\n",
    "\n",
    "ax = fig.gca()\n",
    "ax.contourf(X, Y, Z, zdir='z', levels=9, offset=-0.15, cmap=cm.hot, alpha=0.5)\n",
    "cset = plt.contour(X, Y, Z, cmap=cm.hot, alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.17817167  0.28606963  2.75031092  5.21455222  7.67879352 10.14303481\n",
      " 12.60727611 15.07151741 17.5357587  20.        ]\n",
      "[-1.01358633  1.32125659  3.65609952  5.99094245  8.32578537 10.6606283\n",
      " 12.99547122 15.33031415 17.66515707 20.        ]\n"
     ]
    }
   ],
   "source": [
    "print(np.linspace(min(ULA_data[0]+tULA_data[0]), max(ULA_data[0]+tULA_data[0]), 10))\n",
    "print(np.linspace(min(ULA_data[1]+tULA_data[1]), max(ULA_data[1]+tULA_data[1]), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import normal, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "from time import clock\n",
    "\n",
    "class Potential:\n",
    "    \"\"\" Represents a potential function. \"\"\"\n",
    "    def __init__(self, potential=\"gaussian\", dimension=1):\n",
    "        self.dim = dimension\n",
    "        self.name = potential\n",
    "        # To add a potential, add it to the dictionary below and implement it/its gradient.\n",
    "        self.function, self.gradient, self.gradient2, self.vector_lap_grad = {\n",
    "            \"gaussian\":         (self.gaussian,         self.gaussian_grad,         None, None),\n",
    "            \"double_well\":      (self.double_well,      self.double_well_grad,      self.double_well_grad2, self.double_well_vector_lap_grad),\n",
    "            \"Ginzburg_Landau\":  (self.Ginzburg_Landau,  self.Ginzburg_Landau_grad,  None, None)\n",
    "        }[potential]\n",
    "\n",
    "        # Quantities to store in the Potential class, to avoid needless re-computation.\n",
    "        self.inv_sigma = 1. / np.arange(1, dimension+1, dtype=float) # for Gaussian\n",
    "\n",
    "    def gaussian(self, x):\n",
    "        return 0.5 * np.dot(x, np.multiply(self.inv_sigma, x))\n",
    "\n",
    "    def gaussian_grad(self, x):\n",
    "        return np.multiply(self.inv_sigma, x)\n",
    "\n",
    "    def double_well(self, x):\n",
    "        normx = norm(x)\n",
    "        return 0.25 * normx**4 - 0.5 * normx**2\n",
    "\n",
    "    def double_well_grad(self, x):\n",
    "        return (norm(x)**2 - 1) * x\n",
    "\n",
    "    def double_well_grad2(self, x):\n",
    "        mx = np.matrix(x)\n",
    "        return (norm(x)**2 - 1) * np.identity(self.dim) + 2 * np.transpose(mx) * mx\n",
    "\n",
    "    def double_well_vector_lap_grad(self, x):\n",
    "        return 6*x\n",
    "\n",
    "    def Ginzburg_Landau(self, x, tau=0.01, lamb=1, alpha=10):\n",
    "        d_ = round(self.dim ** (1./3))\n",
    "        x = np.reshape(x, (d_,d_,d_))\n",
    "        nabla_tilde = sum( norm(np.roll(x, -1, axis=a) - x)**2 for a in [0,1,2] )\n",
    "        return 0.5 * (1. - tau) * norm(x)**2 + \\\n",
    "               0.5 * tau * alpha * nabla_tilde + \\\n",
    "               0.25 * tau * lamb * np.sum(np.power(x, 4))\n",
    "\n",
    "    def Ginzburg_Landau_grad(self, x, tau=2.0, lamb=0.5, alpha=0.1):\n",
    "        d_ = round(self.dim ** (1./3))\n",
    "        x = np.reshape(x, (d_,d_,d_))\n",
    "        temp = sum( np.roll(x, sgn, axis=a) for sgn in [-1,1] for a in [0,1,2] )\n",
    "        return ((1. - tau) * x + \\\n",
    "                tau * lamb * np.power(x, 3) + \\\n",
    "                tau * alpha * (6*x - temp)).flatten()\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\" Evaluates a set of Langevin algorithms on given potentials. \"\"\"\n",
    "    def __init__(self, potential=\"gaussian\", dimension=1, N=10**2, burn_in=10**2, N_sim=5, x0=[0], step=0.01, timer=None):\n",
    "        self.dim = dimension\n",
    "        # To add an algorithm, add it to the dictionary below and implement it as a class method.\n",
    "        self.algorithms = {\n",
    "            \"ULA\":     self.ULA,\n",
    "            \"tULA\":    self.tULA,\n",
    "            \"tULAc\":   self.tULAc,\n",
    "            \"MALA\":    self.MALA,\n",
    "            \"RWM\":     self.RWM,\n",
    "            \"tMALA\":   self.tMALA,\n",
    "            \"tMALAc\":  self.tMALAc,\n",
    "            \"tHOLA\":   self.tHOLA,\n",
    "            \"LM\":      self.LM,\n",
    "            \"tLM\":     self.tLM,\n",
    "            \"tLMc\":    self.tLMc\n",
    "        }\n",
    "        self.N = N\n",
    "        self.burn_in = burn_in\n",
    "        self.N_sim = N_sim\n",
    "        self.x0 = x0\n",
    "        self.step = step\n",
    "        self.timer = timer\n",
    "        if timer:\n",
    "            self.N = 10**10 # ~~practically infinity\n",
    "            self.start_time = clock()\n",
    "        self.potential = Potential(potential, dimension)\n",
    "        # invoked by self.potential.funtion(parameters), self.potential.gradient(parameters)\n",
    "    def ULA(self):\n",
    "        x = np.array(self.x0)\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        sqrtstep = np.sqrt(2*self.step)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "            sample[:,i]=x\n",
    "            x += -self.step * self.potential.gradient(x) + sqrtstep * normal(size=self.dim)\n",
    "\n",
    "        return sample #i+1 = no. of iterations\n",
    "\n",
    "    def tULA(self, taming=(lambda g, step: g/(1. + step*norm(g)))):\n",
    "        x = np.array(self.x0)\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        sqrtstep = np.sqrt(2*self.step)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            x += -self.step * taming(self.potential.gradient(x), self.step) + sqrtstep * normal(size=self.dim)\n",
    "        return sample\n",
    "\n",
    "    def tULAc(self):\n",
    "        # coordinate-wise taming function\n",
    "        return self.tULA(lambda g, step: np.divide(g, 1. + step*np.absolute(g)))\n",
    "\n",
    "    def MALA(self):\n",
    "        acc = 0 # acceptance probability\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            U_x, grad_U_x = self.potential.function(x), self.potential.gradient(x)\n",
    "            y = x - self.step * grad_U_x + np.sqrt(2 * self.step) * normal(size=self.dim)\n",
    "            U_y, grad_U_y = self.potential.function(y), self.potential.gradient(y)\n",
    "\n",
    "            logratio = -U_y + U_x + 1./(4*self.step) * (norm(y - x + self.step*grad_U_x)**2 \\\n",
    "                       -norm(x - y + self.step*grad_U_y)**2)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def RWM(self):\n",
    "        acc = 0 # acceptance probability\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            y = x + np.sqrt(2*self.step) * normal(self.dim)\n",
    "            logratio = self.potential.function(x) - self.potential.function(y)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def tMALA(self, taming=(lambda g, step: g/(1. + step*norm(g)))):\n",
    "        acc = 0 # acceptance probability\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            U_x, grad_U_x = self.potential.function(x), self.potential.gradient(x)\n",
    "            tamed_gUx = taming(grad_U_x, self.step)\n",
    "            y = x - self.step * tamed_gUx + np.sqrt(2*self.step) * normal(size=self.dim)\n",
    "            U_y, grad_U_y = self.potential.function(y), self.potential.gradient(y)\n",
    "            tamed_gUy = taming(grad_U_y, self.step)\n",
    "\n",
    "            logratio = -U_y + U_x + 1./(4*self.step) * (norm(y - x + self.step*tamed_gUx)**2 - norm(x - y + self.step*tamed_gUy)**2)\n",
    "            if np.log(uniform(size = 1)) <= logratio:\n",
    "                x = y\n",
    "                if i >= self.burn_in:\n",
    "                    acc += 1\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def tMALAc(self):\n",
    "        return self.tMALA(lambda g, step: np.divide(g, 1. + step * np.absolute(g)))\n",
    "\n",
    "    def tHOLA(self):\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        x = np.array(self.x0)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            norm_x = norm(x)\n",
    "            grad_U = self.potential.gradient(x)\n",
    "            norm_grad_U = norm(grad_U)\n",
    "            grad_U_gamma = grad_U / (1 + (self.step * norm_grad_U)**1.5)**(2./3)\n",
    "            grad2_U = self.potential.gradient2(x)\n",
    "            norm_grad2_U = norm(grad2_U)\n",
    "            grad2_U_gamma = grad2_U / (1 + self.step * norm_grad2_U)\n",
    "\n",
    "            laplacian_grad_U = self.potential.vector_lap_grad(x)\n",
    "            laplacian_grad_U_gamma = laplacian_grad_U / (1 + self.step**0.5 * norm_x * norm(laplacian_grad_U))\n",
    "\n",
    "            grad2_U_grad_U_gamma = np.matmul(grad2_U, grad_U).A1 / (1 + self.step * norm_x * norm_grad2_U * norm_grad_U)\n",
    "\n",
    "            x += -self.step * grad_U_gamma + 0.5 * self.step**2 * (grad2_U_grad_U_gamma - laplacian_grad_U_gamma) + \\\n",
    "                  np.sqrt(2*self.step) * normal(size=self.dim) - np.sqrt(2) * np.matmul(grad2_U_gamma, normal(size=self.dim)).A1 * np.sqrt(self.step**3/3)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def LM(self):\n",
    "        x = np.array(self.x0)\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        sqrtstep = np.sqrt(0.5 * self.step)\n",
    "        gaussian = normal(size=self.dim)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            gaussian_plus1 = normal(size=self.dim)\n",
    "            x += -self.step * self.potential.gradient(x) + sqrtstep * (gaussian + gaussian_plus1) * 0.5\n",
    "            gaussian = gaussian_plus1\n",
    "        return sample\n",
    "\n",
    "    def tLM(self, taming=(lambda g, step: g/(1. + step * norm(g)))):\n",
    "        x = np.array(self.x0)\n",
    "        sample = np.zeros((self.dim, self.N + self.burn_in), dtype=float)\n",
    "        sqrtstep = np.sqrt(0.5 * self.step)\n",
    "        gaussian = normal(size=self.dim)\n",
    "\n",
    "        for i in range(self.burn_in + self.N):\n",
    "            if self.timer and clock() - self.start_time > self.timer:\n",
    "                break\n",
    "\n",
    "            sample[:,i]=x\n",
    "            gaussian_plus1 = normal(size=self.dim)\n",
    "            x += -self.step * taming(self.potential.gradient(x), self.step) + sqrtstep * (gaussian + gaussian_plus1) * 0.5\n",
    "            gaussian = gaussian_plus1\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def tLMc(self):\n",
    "        return self.tLM(lambda g, step: np.divide(g, 1. + step * np.absolute(g)))\n",
    "\n",
    "    def sampler(self, algorithm=\"ULA\"):\n",
    "        if self.timer:\n",
    "            self.start_time = clock()\n",
    "        return self.algorithms[algorithm]()\n",
    "\n",
    "potential = 'double_well'\n",
    "d = 2\n",
    "N = 10**6\n",
    "burn_in = 10**4\n",
    "N_sim = 1\n",
    "x0 = np.array([0] + [0]*(d-1), dtype=float)\n",
    "step = 0.1\n",
    "\n",
    "# TIMER MODE: number of seconds which we allow the algorithms to run\n",
    "# To run normally without a timer, omit the last parameter\n",
    "timer = 2.5\n",
    "\n",
    "e = Evaluator(potential, dimension=d, N=N, burn_in=burn_in, N_sim=N_sim, x0=x0, step=step)\n",
    "\n",
    "\n",
    "MALA_data = e.sampler(\"tULA\")\n",
    "#tULA_data = e.sampler(\"tULA\")\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.title(\"Trace\" )\n",
    "# plt.plot(ULA_data[0],ULA_data[1],'r')\n",
    "# plt.plot(tULA_data[0],tULA_data[1],'g')\n",
    "#\n",
    "# from matplotlib import cm\n",
    "# from scipy.stats import multivariate_normal as MVN\n",
    "#\n",
    "# \"\"\"Plot heatmap of 2D MVN distribution \"\"\"\n",
    "# # Our 2-dimensional distribution will be over variables X and Y\n",
    "# N = 600\n",
    "# X = np.linspace(min(np.append(ULA_data[0], tULA_data[0])), max(np.append(ULA_data[0],tULA_data[0])), N)\n",
    "# Y = np.linspace(min(np.append(ULA_data[1], tULA_data[1])), max(np.append(ULA_data[1],tULA_data[1])), N)\n",
    "# X, Y = np.meshgrid(X, Y)\n",
    "#\n",
    "# # Mean vector and covariance matrix\n",
    "# mu = np.array([0., 0])\n",
    "# Sigma = np.diag(np.arange(1, 3, dtype=float))\n",
    "#\n",
    "# # Pack X and Y into a single 3-dimensional array\n",
    "# pos = np.empty(X.shape + (2,))\n",
    "# pos[:, :, 0] = X\n",
    "# pos[:, :, 1] = Y\n",
    "#\n",
    "# F = MVN(mu, Sigma)\n",
    "# Z = F.pdf(pos)\n",
    "#\n",
    "# ax = fig.gca()\n",
    "# ax.contourf(X, Y, Z, zdir='z', levels=9, offset=-0.15, cmap=cm.hot, alpha=0.5)\n",
    "# cset = plt.contour(X, Y, Z, cmap=cm.hot, alpha=0.5)\n",
    "#\n",
    "# plt.show()\n",
    "\n",
    "for i in range(1,d):\n",
    "    plt.hist(MALA_data[i,burn_in:-1], density=True, bins=100)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
